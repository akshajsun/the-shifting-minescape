<p align="center">
  <img src="img.png" alt="The Shifting Minescape Logo" width="800"/>
</p>

<h1 align="center">The Shifting Minescape</h1>

<p align="center">
  <em>A competitive multi-agent reinforcement learning maze game where AI bots evolve in real-time as you race through a dynamically shifting underground mine.</em>
</p>

<p align="center">
  <strong>Where Bots Learn, Mines Shift, and Victory Awaits.</strong>
</p>

---

## ğŸ® What Is This?

**The Shifting Minescape** is an advanced game combining cutting-edge reinforcement learning with real-time procedural maze generation. You race against 1-4 AI bots inside an ever-changing underground mine where:

- **Walls crumble and new paths emerge** in real-time during gameplay
- **AI bots learn and improve** with each playthrough using Deep Q-Networks (DQN)
- **You control difficulty, bot intelligence, and learning rates** via an intuitive developer panel
- **Premium mining aesthetic** with polished animations, glowing ore deposits, and particle effects
- **All agents compete simultaneously** in a high-stakes race to the goal

---

## âœ¨ Key Features

### ğŸŒ€ Dynamic Maze System
- Real-time maze transformation during gameplayâ€”not between rounds
- Walls crumble and rebuild with animated transitions
- Configurable shift frequency (2â€“30 seconds) and complexity
- Procedurally generated layouts ensure variety every match

### ğŸ¤– Reinforcement Learning Bots
- Deep Q-Network (DQN) agents that actively learn and improve
- Bots observe local maze state, goal distance, and agent positions
- Reward shaping encourages efficient pathfinding and goal completion
- Trained models persist between sessionsâ€”bots get smarter over time
- Watch bot learning curves improve in real-time

### âš™ï¸ Developer Control Panel
Configure gameplay on-the-fly with smooth, animated sliders:
- **Bot Intelligence:** Dumb, Learning, Expert, or Custom (set training episodes)
- **Learning Rate (Î±):** Control how fast bots adapt (0.0â€“1.0)
- **Discount Factor (Î³):** Balance short-term vs. long-term planning (0.0â€“1.0)
- **Exploration vs. Exploitation:** Fine-tune bot randomness and convergence
- **Maze Shift Frequency:** 2â€“30 seconds (updates instantly)
- **Maze Complexity:** Adjust branch density, dead-ends, corridor width
- **Bot Count:** 1â€“4 opponents, selectable
- **Collision Mechanics:** Stun duration, collision radius, damage toggle

### ğŸ† Competitive Gameplay
- Real-time leaderboard tracking positions and times
- Collision system stuns rivals and creates tactical opportunities
- Minimap showing detected maze layout and all agent positions
- Stats tracking: completion time, path efficiency, win rates
- Replay system to analyze bot strategies


---

## ğŸš€ Quick Start

### Installation
```bash
git clone https://github.com/yourusername/the-shifting-minescape.git
cd the-shifting-minescape
npm install
```

### Development
```bash
npm run dev
# Game runs on http://localhost:3000
```

### Production Build
```bash
npm run build
npm run serve
```

---

## ğŸ® How to Play

1. **Launch the game** â†’ Beautiful animated menu appears
2. **Configure settings** (optional) â†’ Adjust bot count, difficulty, maze shift speed
3. **Start Game** â†’ Race to the goal against AI bots
4. **Navigate & Compete** â†’ Avoid dead-ends, watch for maze shifts, outrun rivals
5. **Win or Learn** â†’ View detailed stats and bot learning curves post-game

### Controls
| Action | Key(s) |
|--------|--------|
| Move Up | W / â†‘ |
| Move Down | S / â†“ |
| Move Left | A / â† |
| Move Right | D / â†’ |
| Pause / Settings | ESC |

---

## ğŸ› ï¸ Technology Stack

| Layer | Technology |
|-------|-----------|
| **Game Engine** | Phaser 3 |
| **RL Framework** | TensorFlow.js |
| **State Management** | Redux |
| **Build Tool** | Vite |
| **Styling** | SCSS / CSS-in-JS |
| **Rendering** | WebGL / Canvas (60+ FPS) |
| **Storage** | IndexedDB (bot models, scores) |

---

## ğŸ“ Project Structure

```
src/
â”œâ”€â”€ main.js                      # Entry point
â”œâ”€â”€ config/
â”‚   â””â”€â”€ GameConfig.js            # Global configuration & constants
â”œâ”€â”€ scenes/
â”‚   â”œâ”€â”€ MenuScene.js             # Animated main menu
â”‚   â”œâ”€â”€ GameScene.js             # Main gameplay loop
â”‚   â”œâ”€â”€ PauseScene.js            # Pause & developer panel
â”‚   â””â”€â”€ VictoryScene.js          # Results & stats breakdown
â”œâ”€â”€ maze/
â”‚   â”œâ”€â”€ MazeGenerator.js         # Procedural generation (Eller's algorithm)
â”‚   â””â”€â”€ MazeShifter.js           # Dynamic maze transformation
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ Agent.js                 # Base agent class
â”‚   â”œâ”€â”€ Player.js                # Player-controlled agent
â”‚   â””â”€â”€ Bot.js                   # AI bot with RL integration
â”œâ”€â”€ ai/
â”‚   â”œâ”€â”€ DQNAgent.js              # Deep Q-Network implementation
â”‚   â””â”€â”€ ReplayBuffer.js          # Experience replay for training
â”œâ”€â”€ physics/
â”‚   â”œâ”€â”€ Collision.js             # Collision detection & response
â”‚   â””â”€â”€ Movement.js              # Agent movement & physics
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ HUD.js                   # Real-time HUD (leaderboard, stats)
â”‚   â”œâ”€â”€ Minimap.js               # Animated minimap overlay
â”‚   â””â”€â”€ SettingsPanel.js         # Developer control sliders
â”œâ”€â”€ effects/
â”‚   â”œâ”€â”€ Particles.js             # Particle system (dust, debris)
â”‚   â”œâ”€â”€ Animations.js            # Smooth tweens & transitions
â”‚   â””â”€â”€ Lighting.js              # Dynamic lighting & glow
â””â”€â”€ utils/
    â”œâ”€â”€ MathUtils.js             # Helper functions
    â”œâ”€â”€ StorageUtils.js          # IndexedDB model persistence
    â””â”€â”€ AudioManager.js          # Sound & music playback
```

---

## ğŸ§  Reinforcement Learning Details

### Algorithm: Deep Q-Network (DQN)
- **State Space:** Discretized grid around agent + distance to goal + nearby agent positions
- **Action Space:** 4â€“8 directions (4-way or 8-way movement)
- **Reward Shaping:**
  - âœ… +1.0 for moving closer to goal
  - âœ… +10.0 for reaching goal
  - âœ… +0.5 for efficient path (no backtracking)
  - âŒ -0.1 per step (encourages speed)
  - âŒ -1.0 for collision (penalizes aggression)
  - âŒ -0.5 for infinite loops

### Neural Network Architecture
- **Input Layer:** Flattened state representation (50â€“100 neurons)
- **Hidden Layers:** 2â€“3 fully connected layers (64â€“128 neurons, ReLU activation)
- **Output Layer:** Q-values for each action (4â€“8 outputs)

### Training
- Bots train via experience replay with batch size of 32
- Learning happens in background during idle time and between rounds
- Models are serialized and persisted in IndexedDB
- Transfer learning allows bots to fine-tune on new maze complexities

---

## ğŸ§ª Testing & Performance

- **Target FPS:** 60+ (stable on mid-range devices)
- **Input Latency:** <100ms player controls
- **Bot Decision Rate:** Update every 100â€“200ms (balance responsiveness + compute)
- **Maze Generation:** <50ms per full regeneration
- **Model Training:** Happens asynchronously via Web Workers

---

## ğŸ“Š Game Metrics & Stats

Every game tracks:
- **Completion Time:** How fast you reached the goal
- **Path Efficiency:** Ratio of optimal vs. actual path length
- **Distance Traveled:** Total tiles traversed
- **Collisions:** Number of agent-agent collisions
- **Bot Learning Curve:** Reward per episode, convergence rate
- **Win Rate:** Player vs. each bot over session

---

## ğŸ¤ Contributing

Contributions welcome! Areas for enhancement:
- Advanced RL algorithms (Policy Gradients, A3C)
- Additional visual themes & customization
- Mobile touch controls optimization
- Multiplayer networking layer
- Advanced procedural generation techniques

To contribute:
1. Fork the repo
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the **MIT License** â€” see the [LICENSE](LICENSE) file for details.

---

## ğŸ’¡ Inspiration & Credits

- **RL Concepts:** Deep Q-Networks (Mnih et al., 2013)
- **Game Engine:** [Phaser 3 Documentation](https://phaser.io)
- **RL Framework:** [TensorFlow.js](https://www.tensorflow.org/js)
- **Mining Aesthetic:** Inspired by retro mining games, modern minimalism, and premium game design

---

## ğŸš€ Deploy

The game is optimized for web deployment:
- **Vercel:** `npm run build && vercel deploy`
- **Netlify:** Connect repo, auto-deploys on push
- **Firebase:** `npm run build && firebase deploy`

---

## ğŸ“¬ Contact & Support

Have questions, bugs, or feature requests? Open an [issue](https://github.com/akshajsun/the-shifting-minescape/issues) or reach out!

---

<p align="center">
  <strong>Made with â›ï¸ and ğŸ¤–</strong>
</p>

<p align="center">
  <em>The Shifting Minescape â€” Where Bots Learn, Mines Shift, and Victory Awaits.</em>
</p>
